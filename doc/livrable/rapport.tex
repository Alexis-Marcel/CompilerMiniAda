\documentclass[french,a4paper]{article}
\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{pdfpages}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{tikz}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}

\usetikzlibrary{graphs,graphs.standard,arrows,shapes.multipart,chains,positioning,quotes}
\renewcommand{\contentsname}{Table des matières}
\newcommand{\tabitem}{\textbullet~~}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\usepackage{multirow}
\graphicspath{{img/}}
\title{Projet de compilation}
\usepackage[bottom=2.5cm,top=2.5cm,left=2.5cm,right=2.5cm]{geometry}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amstex}
\setcounter{MaxMatrixCols}{20}
\author{Noé Steiner - Alexis Marcel - Lucas Laurent}
\date{24 Mai 2023}
\lstset{
    language=C,                % choose the language of the code
    numbers=left,              % where to put the line-numbers
    stepnumber=1,              % the step between two line-numbers.
    numbersep=10pt,            % how far the line-numbers are from the code
    tabsize=2,                 % tab size
    showspaces=false,          % show spaces adding particular underscores
    showstringspaces=false,    % underline spaces within strings
    breaklines=true,           % sets automatic line breaking
    frame=single,              % adds a frame around the code
    rulecolor=\color{black},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    commentstyle=\color{gray},
    morecomment=[l][\color{magenta}]{\#},
    extendedchars=true,        % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
    captionpos=b,              % sets the caption-position to bottom
    basicstyle=\ttfamily,
    mathescape=true,
    language=Java,
}

\begin{document}

%\maketitle

    \begin{titlepage}
        \begin{center}

            \includegraphics[width=0.5\textwidth]{tele_univ}

            \textsc{\Large Rapport d'activité du Projet de compilation}\\[1.5cm]

            \HRule \\[0.4cm]
            { \huge \bfseries Développement d'un compilateur pour le langage CanAda\\[0.4cm] }

            \HRule \\[2cm]

            \begin{minipage}{0.4\textwidth}
                \begin{flushleft} \large
                Alexis MARCEL\\
                Lucas LAURENT\\
                Noé STEINER\\
                \end{flushleft}
            \end{minipage}
            \begin{minipage}{0.4\textwidth}
                \begin{flushright} \large
                \emph{Responsables du module :}\\
                M. Olivier FESTOR\\
                Mme. Suzanne COLLIN\\
                \end{flushright}
            \end{minipage}

            \vfill

            {\large 15 Janvier 2024}

        \end{center}
    \end{titlepage}
    \newpage
    \tableofcontents
    \newpage
    \section{Contexte du projet}\label{sec:contexte-du-projet}
    Ce rapport présente le projet réalisé dans le cadre du module PCL1 de la deuxième année du cycle ingénieur à TELECOM Nancy.
    L'objectif principal est de développer, en groupe, un compilateur pour le langage \textit{canAda}, une version simplifiée d'Ada.
    Ce projet est une opportunité d'approfondir nos compétences en analyse lexicale et syntaxique ainsi que la construction d'un arbre abstrait.

    \section{Introduction}\label{sec:introduction}
    Dans le cadre de nos études, la compréhension et le développement de compilateurs se révèlent cruciaux car ils permettent de mieux comprendre les principes fondamentaux de l'informatique, comme la structure des langages de programmation, l'analyse syntaxique ou encore les arbres abstraits.
    Cette connaissance est essentielle pour optimiser les performances des programmes, assurer leur sécurité, et développer des logiciels fiables et efficaces.
    Le projet \textit{canAda} s'inspire d'Ada, un langage connu pour sa fiabilité et sa sécurité.
    Ce travail nous plonge dans la complexité de la compilation, nous préparant à des applications concrètes dans divers secteurs tels que les systèmes embarqués, la défense, ou l'aéronautique.
    En développant un compilateur, nous affrontons non seulement les défis techniques relatifs à la conception d'un tel compilateur mais cela constitue aussi une base de connaissances fondamentale pour nous, futurs ingénieurs.
    Nous avons pris comme décision de faire ce projet en Java car nous avions envie d'approfondir notre connaissance de ce langage et de ses outils.

    \section{Grammaire}\label{sec:grammaire}

    \subsection{Présentation}\label{subsec:presentation}
    Le sujet nous a fourni une grammaire associée au langage \textit{canAda}.
    Cette grammaire est une version simplifiée de la grammaire du langage Ada et était sous une forme abstraire avec notamment des regex.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{grammaire_init}
        \caption{Grammaire initiale du Sujet}\label{fig:figure}
    \end{figure}

    \subsection{Étapes de transformation de la Grammaire}\label{subsec:etapes-de-transformation-de-la-grammaire}

    \subsubsection{Grammaire originale en BNF}\label{subsec:grammaire-originale-en-bnf}

    La grammaire initiale du langage \textit{canAda}, avant sa transformation en grammaire LL(1), se présente comme suit en BNF sans les regex:

    \begin{lstlisting}[keywordstyle=\color{black},label={lst:lstlisting}]
fichier -> $withAda.Text$_$IO$ $;$ $useAda.Text$_$IO$ $;$ $procedure$ $ident$ $is$ <decls> $begin$ <instrs> $end$ <hasident> $;$ $EOF$

decl -> $type$ $ident$ $;$
        | $type$ $ident$ $is$ $access$ $ident$ $;$
        | $type$ $ident$ $is$ $record$ <champs> $end$ $record$ $;$
        | <identsep> $:$ <type> <typexpr> $;$
        | $procedure$ $ident$ <hasparams> $is$ <decls> $begin$ <instrs> $end$ <hasident> $;$
        | $function$ $ident$ <hasparams> $return$ <type> $is$ <decls> $begin$ <instrs> $end$ <hasident> $;$

decls -> <decl> <decls>
        | $\epsilon$

hasident -> $ident$
            | $\epsilon$

identsep -> $ident$ $,$ <identsep>
            | ident

champ -> <identsep> $:$ <type> $;$

champs -> <champ> <champs>
            | <champ>

type -> $ident$
        | $access$ ident

params -> $($ <paramsep> $)$

hasparams -> <params>
            | $\epsilon$

paramsep -> <param> $;$ <paramsep>
            | <param>

typexpr -> $:=$ <expr>
            | $\epsilon$

param -> <identsep> $:$ <mode> <type>

mode -> $in$
        | $in$ $out$
        | $\epsilon$

expr -> $entier$
        | $caractère$
        | $true$
        | $false$
        | $null$
        | $($ <expr> $)$
        | <acces>
        | <expr> <operateur> <expr>
        | $not$ <expr>
        | $-$ <expr>
        | $new$ $ident$
        | $ident$ ( <exprsep> )
        | $character$ $'$ $val$ $($ <expr> $)$

exprsep -> <expr> $,$ <exprsep>
            | <expr>

hasexpr -> <expr>
            | $\epsilon$

instr -> <acces> $:=$ <expr> ;
            | $ident$ $;$
            | $ident$ ( <exprsep> ) $;$
            | $return$ <hasexpr> $;$
            | $begin$ <instrs> $end$ $;$
            | $if$ <expr> $then$ <instrs> <elsif> <else> $end$ $if$ $;$
            | $for$ $ident$ $in$ <hasreverse> <expr> .. <expr> $loop$ <instrs> $end$ $loop$ $;$
            | $while$ <expr> $loop$ <instrs> $end$ $loop$ $;$

elsif -> $elsif$ <expr> $then$ <instrs> <elsif>
            | $\epsilon$

else -> $else$ <instrs>
            | $\epsilon$

hasreverse -> $reverse$
                | $\epsilon$

instrs -> <instr> <instrs>
            | <instr>

operateur -> $=$ | $/=$ | $<$ | $<=$ | $>$ | $>=$ | $+$ | $-$ | $*$ | $/$ | $rem$ | $and$ | $and$ $then$ | $or$ | $or$ $else$

acces -> $ident$
        | <expr> $.$ $ident$

    \end{lstlisting}

    \subsubsection{Élimination de la Récursivité à Gauche}
    La grammaire initiale comportait plusieurs instances de récursivité à gauche.
    Par exemple, les deux règles suivantes:
    \begin{lstlisting}[label={lst:lstlisting2}]
expr -> <acces>
acces -> $ident$ | <expr> . ident
    \end{lstlisting}
    ont été transformées en:
    \begin{lstlisting}[label={lst:lstlisting3}]
expr -> [$\dots$] -> primary
primary -> $ident$ <primary2>
primary2 -> $($ <exprsep> $)$ <acces> | <acces>
acces -> $.$ ident <acces> | $\epsilon$
    \end{lstlisting}
    Comme la priorisation des calculs a beaucoup impacté la structure de la grammaire, on note [\dots] pour représenter l'enchainement de règles permettant de se retrouver dans le cas de la règle \textit{expr} de départ.
    Cette modification élimine la (double ici) récursivité à gauche, rendant la grammaire adaptée pour une analyse LL(1).
    Une autre récursivité à gauche a été supprimé mais elle a été faite aussi à travers la priorisation des règles.

    \subsubsection{Factorisation à Gauche}
    La factorisation à gauche a été nécessaire pour certaines règles.
    Par exemple, les règles suivantes:
    \begin{lstlisting}[label={lst:lstlisting4}]
exprsep -> <expr> $,$ <exprsep>
exprsep -> <expr>
    \end{lstlisting}
    ont été réécrites en:
    \begin{lstlisting}[label={lst:lstlisting5}]
exprsep -> <expr> <exprsep$'$>
exprsep$'$ -> $,$ <expr> <exprsep$'$> | $\epsilon$
    \end{lstlisting}
    Ceci assure que la règle peut être analysée de manière déterministe en LL(1).

    \subsubsection{Gestion des Priorités de Calculs}
    Pour gérer correctement les priorités des opérations, la grammaire a été ajustée notamment au niveau des règles de \textit{expr}.
    Par exemple, les opérations de \textit{Ou} et \textit{Et} ont été séparées des opérations d'addition et de soustraction pour respecter leur priorité selon le sujet, par exemple:
    \begin{lstlisting}[label={lst:lstlisting6}]
        expr -> <expr> <operateur> <expr>
    \end{lstlisting}
    a été réécrite en partie de cette manière:
    \begin{lstlisting}[label={lst:lstlisting7}]
expr -> <or_expr>
or_expr -> <and_expr> <or_expr$'$>
or_expr$'$ -> $or$ <or_expr$'$2> | $\epsilon$
or_expr$'$2 -> <and_expr> <or_expr$'$>
or_expr$'$2 -> $else$ <and_expr> <or_expr$'$>
and_expr -> <not_expr> <and_expr$'$>
[$\dots$]
unary_expr -> $-$ <unary_expr>
unary_expr -> <primary>
primary -> $entier$
primary -> $caractère$
primary -> $true$
primary -> $false$
primary -> $null$
primary -> $($ <expr> $)$
primary -> $ident$ <primary2>
primary -> $new$ $ident$
primary -> $character$ $'$ $val$ ( <expr> )
    \end{lstlisting}
    Cela permet de respecter la hiérarchie des opérations dans les expressions arithmétiques et logiques.

    Les ensembles de sélection distincts ont été calculés pour assurer une sélection univoque lors de l'analyse.

    Ces étapes illustrent comment la grammaire initiale a été transformée en une grammaire LL(1), adaptée pour une analyse syntaxique efficace et précise du langage \textit{canAda}

    \subsection{Grammaire Transformée en LL(1)}\label{subsec:grammaire-transformee-en-ll(1)}
    La grammaire transformée en LL(1) se présente comme suit:
    \begin{lstlisting}[label={lst:lstlisting9}]
fichier -> $withAda.Text$_$IO$ $;$ $useAda.Text$_$IO$ $;$ $procedure$ $ident$ $is$ decls $begin$ instrs $end$ hasident $;$ $EOF$
decl -> $type$ $ident$ hasischoose $;$
decl -> identsep $:$ type_n typexpr $;$
decl -> $procedure$ ident hasparams $is$ decls $begin$ instrs $end$ hasident $;$
decl -> $function$ $ident$ hasparams $return$ type_n $is$ decls $begin$ instrs $end$ hasident $;$

hasischoose -> $is$ accorrec | $\epsilon$

accorrec -> $access$ $ident$
accorrec -> $record$ champs $end$ $record$

decls -> decl decls
decls -> $\epsilon$

hasident -> $ident$
hasident -> $\epsilon$

identsep -> $ident$ identsep2

identsep2 -> $,$ identsep
identsep2 -> $\epsilon$

champ -> identsep $:$ type_n $;$

champs -> champ champs2

champs2 -> champs | $\epsilon$

type_n -> $ident$
type_n -> $access$ $ident$

params -> $($ paramsep $)$

hasparams -> params
hasparams -> $\epsilon$

paramsep -> param paramsep2

paramsep2 -> $;$ paramsep
paramsep2 -> $\epsilon$

typexpr -> $:=$ expr
typexpr -> $\epsilon$

param -> identsep $:$ mode type_n

mode -> $in$ modeout
mode -> $\epsilon$

modeout -> $out$
modeout -> $\epsilon$

expr -> or_expr

or_expr -> and_expr or_expr$'$

or_expr$'$ -> $or$ or_expr$'$2
or_expr$'$ -> $\epsilon$

or_expr$'$2 -> and_expr or_expr$'$
or_expr$'$2 -> $else$ and_expr or_expr$'$

and_expr -> not_expr and_expr$'$

and_expr$'$ -> $and$ and_expr$'$2
and_expr$'$ -> $\epsilon$

and_expr$'$2 -> not_expr and_expr$'$
and_expr$'$2 -> $then$ not_expr and_expr$'$

not_expr -> equality_expr not_expr$'$

not_expr$'$ -> $not$ equality_expr not_expr$'$
not_expr$'$ -> $\epsilon$

equality_expr -> relational_expr equality_expr$'$

equality_expr$'$ -> $=$ relational_expr equality_expr$'$
equality_expr$'$ -> $/=$ relational_expr equality_expr$'$
equality_expr$'$ -> $\epsilon$

relational_expr -> additive_expr relational_expr$'$

relational_expr$'$ -> $<$ additive_expr relational_expr$'$
relational_expr$'$ -> $<=$ additive_expr relational_expr$'$
relational_expr$'$ -> $>$ additive_expr relational_expr$'$
relational_expr$'$ -> $>=$ additive_expr relational_expr$'$
relational_expr$'$ -> $\epsilon$

additive_expr -> multiplicative_expr additive_expr$'$

additive_expr$'$ -> $+$ multiplicative_expr additive_expr$'$
additive_expr$'$ -> $-$ multiplicative_expr additive_expr$'$
additive_expr$'$ -> $\epsilon$

multiplicative_expr -> unary_expr multiplicative_expr$'$

multiplicative_expr$'$ -> $*$ unary_expr multiplicative_expr$'$
multiplicative_expr$'$ -> $/$ unary_expr multiplicative_expr$'$
multiplicative_expr$'$ -> $rem$ unary_expr multiplicative_expr$'$
multiplicative_expr$'$ -> $\epsilon$

unary_expr -> $-$ unary_expr
unary_expr -> primary

primary -> $entier$
primary -> $caractère$
primary -> $true$
primary -> $false$
primary -> $null$
primary -> $($ expr $)$
primary -> $ident$ primary2
primary -> $new$ $ident$
primary -> $character$ $'$ $val$ $($ expr $)$

primary2 -> $($ exprsep $)$ acces
primary2 -> acces

exprsep -> expr exprsep2

exprsep2 -> $,$ exprsep
exprsep2 -> $\epsilon$

hasexpr -> expr
hasexpr -> $\epsilon$

instr -> $ident$ instr2
instr -> $return$ hasexpr $;$
instr -> $begin$ instrs $end$ $;$
instr -> $if$ expr $then$ instrs elifn elsen $end$ $if$ $;$
instr -> $for$ ident $in$ hasreverse expr $..$ expr $loop$ instrs $end$ $loop$ $;$
instr -> $while$ expr $loop$ instrs $end$ $loop$ $;$

instr2 -> instr3 $:=$ expr $;$
instr2 -> $($ exprsep $)$ instr3 hasassign $;$
instr2 -> $;$

instr3 -> $.$ $ident$ instr3
instr3 -> $\epsilon$

hasassign -> $:=$ expr
hasassign -> $\epsilon$

elifn -> $elif$ expr $then$ instrs elifn
elifn -> $\epsilon$

elsen -> $else$ instrs
elsen -> $\epsilon$

hasreverse -> $reverse$
hasreverse -> $\epsilon$

instrs -> instr instrs2

instrs2 -> instr instrs2
instrs2 -> $\epsilon$

acces -> $.$ $ident$ acces
acces -> $\epsilon$
    \end{lstlisting}

    \subsection{Table LL(1)}\label{subsec:table-ll(1)}

    A l'aide de la grammaire transformée en LL(1), nous avons pu construire la table LL(1) suivante pour produire notre \textit{Parser}.
    Ci-dessous, nous présentons une partie de la table LL(1) pour des raisons de lisibilité.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{partial_table}
        \caption{Table partielle LL(1)}\label{fig:figure2}
    \end{figure}

    \section{Analyse Lexicale pour canAda}\label{sec:analyse-lexicale-pour-canada}

    L'analyse lexicale, une étape cruciale dans le processus de compilation, est gérée par notre classe \textit{Lexer}.
    Cette classe est responsable de la conversion du code source en une série de tokens, facilitant ainsi l'analyse syntaxique ultérieure.
    Elle contient un \textit{PeekingReader} codé par nos soins, qui permet de lire dans le flux de caractères pour identifier correctement les tokens complexes tout en conservant ce qui a été lu et en lisant caractère par caractère.
    Elle contient également un \textit{ErrorService} qui permet de gérer les erreurs lexicales mais aussi une map de mots clés qui permet de gérer les mots clés du langage, les opérateurs et les symboles.

    \subsection{Structure et Fonctionnement du Lexer}\label{subsec:structure-et-fonctionnement-du-lexer}

    La classe \textit{Lexer} lit le code source et identifie les différents tokens en se basant sur un ensemble de règles prédéfinies, il est codé à l'aide du pattern \textit{Singleton} pour éviter d'avoir plusieurs instances de la classe.
    Chaque token est une instance de la classe \textit{Token}, qui contient des informations telles que le type de token et la valeur lexicale associée contenu dans l'enum \textit{Tag}.

    \subsection{Gestion des Tokens}\label{subsec:gestion-des-tokens}

    Des classes spécifiques, comme \textit{Tag} et \textit{PeekingReader}, sont utilisées pour catégoriser les tokens et gérer efficacement la lecture en avance du code source.
    La classe \textit{Tag} définit les différents types de tokens, c'est une enum, tandis que \textit{PeekingReader} permet de lire en avance dans le flux de caractères pour identifier correctement les tokens complexes en se passant donc d'un automate à états finis.
    Cela repose sur deux fonctions complexes qui permettent de lire le flux de caractères et de déterminer si le caractère courant est la fin d'un token.

    \begin{lstlisting}[language=Java,label={lst:lstlisting1}]
/**
    * Check if the current character is the end of a token
    *
    * @return true if the current character is the end of a token, false otherwise
    */
private boolean isEndOfToken() {
    char current = (char) currentChar;
    int nextInt = this.reader.peek(1);
    char next = (char) nextInt;

    boolean isCurrentLetterOrDigit = Character.isLetterOrDigit(current) || current == '_';
    boolean isNextLetterOrDigit = Character.isLetterOrDigit(next) || next == '_';
    boolean isNextWhitespace = Character.isWhitespace(next);

    // If the current character is a whitespace or the end of the file, the current character is the end of the token
    if (nextInt == -1 || isNextWhitespace) {
        return true;
    }
    // If the current character is an identifier or an integer, the next character must not be a letter or a digit
    if (isCurrentLetterOrDigit) {
        return !isNextLetterOrDigit;
    }

    Token token = this.matchToken(lexeme.toString());

    // If the current character is a token and the next character is not a token, the current character is the end of the token
    if (token.tag() != Tag.UNKNOWN) {
        Token nextToken = this.matchToken(lexeme.toString() + next);
        return nextToken.tag() == Tag.UNKNOWN;
    }

    return false;
}
    \end{lstlisting}

    \begin{lstlisting}[label={lst:lstlisting12}]
public Token nextToken() {

    while ((this.currentChar = this.reader.read()) != -1) {

        if (this.isComment()) {
            this.skipComment();
        } else if (Character.isWhitespace((char) currentChar)) {
            this.skipWhitespace();
        } else if (isCharacterLiteral()) {
            return this.readCharacterLiteral();
        } else {
            lexeme.append((char) currentChar);
            if (this.isEndOfToken()) {
                Token token = this.matchToken(lexeme.toString());
                lexeme.setLength(0); // clear the StringBuilder
                if (token.tag() == Tag.UNKNOWN) {
                    this.errorService.registerLexicalError(new UnknownTokenException(token));
                }
                return token;
            }
        }
    }

    this.reader.close();
    return new Token(Tag.EOF, this.reader.getCurrentLine(), lexeme.toString());
}
    \end{lstlisting}

    \subsection{Optimisation et Fiabilité}\label{subsec:optimisation-et-fiabilite}

    Le \textit{Lexer} est conçu pour être à la fois rapide et fiable, capable d'identifier précisément les tokens même dans des cas de syntaxe complexe grâce aux fonctions présentées ci-dessus.
    Cette précision est essentielle pour garantir une analyse syntaxique sans erreur dans les étapes suivantes du processus de compilation.
    Le fait de se passer d'un automate à états finis permet d'optimiser le temps d'exécution du \textit{Lexer}.

    \section{Analyse Syntaxique}\label{sec:analyse-syntaxique}

    \subsection{Structure et Fonctionnement}\label{subsec:structure-et-fonctionnement}

    La classe \textit{Parser} a été conçue pour analyser les programmes écrits dans le langage \textit{canAda}, il est codé, lui aussi, à l'aide du pattern \textit{Singleton} pour éviter d'avoir plusieurs instances de la classe.
    Il contient le token courant et l'analyseur lexical qui est utilisé pour analyser le programme source.
    Chaque méthode de cette classe correspond à un non-terminal de la grammaire LL(1) et est responsable de l'analyse d'une structure syntaxique spécifique du langage.
    Par exemple, une méthode \textit{expr()} est utilisée pour analyser les expressions, correspondant au non-terminal \textit{expr} de la grammaire.
    Ces méthodes sont appelées récursivement pour construire l'arbre syntaxique du programme source.
    En fonction du token courant, on applique la règle associée à ce token d'après la table LL(1) construite précédemment.
    Si des terminaux sont dans cette règle, ils ont lu à travers la fonction \textit{analyseTerminal()} trouvable dans la suite du rapport qui permet de vérifier si le token courant correspond bien au terminal attendu.
    Sinon on appelle la méthode associée au non-terminal de la règle et ainsi de suite \dots

    \begin{lstlisting}[label={lst:lstlisting10}]
@PrintMethodName
private void expr() {
    switch (this.currentToken.tag()) {
        case IDENT, OPEN_PAREN, DOT, ENTIER, CARACTERE, TRUE, FALSE, NULL, NEW, CHARACTER -> {
            or_expr();
        }
    }
}
    \end{lstlisting}


    \subsection{Interaction avec l'Analyseur Lexical}\label{subsec:interaction-avec-l'analyseur-lexical}

    Le \textit{Parser} interagit étroitement avec l'analyseur lexical, recevant un flux de tokens qui sont analysés selon les règles de la grammaire.
    Cette interaction est cruciale pour la décomposition correcte du programme source en ses composants syntaxiques.
    On lit les tokens un par un et on les compare avec les règles de la grammaire.
    Si le token correspond à la règle, on passe au token suivant.
    Si le token ne correspond pas à la règle, on génère une erreur syntaxique.

    \begin{lstlisting}[label={lst:lstlisting11}]
@PrintMethodName
private void analyseTerminal(Tag tag) {
    System.out.println("\t\t-> " + this.currentToken);
    if (!(this.currentToken.tag() == tag)) {
        Token expectedToken = new Token(tag, this.currentToken.line(), TagHelper.getTagString(tag));
        if (expectedToken.tag() == Tag.SEMICOLON) {
            this.errorService.registerSyntaxWarning(new MissingSemicolonException(this.currentToken));
        } else {
        this.errorService.registerSyntaxError(new UnexpectedTokenException(expectedToken, this.currentToken));}
    }
    // Contient le prochain token ou <EOF, currentLine,""> si fin de fichier
    if (this.currentToken.tag() == Tag.EOF) {
        return;
    }
    this.currentToken = lexer.nextToken();
}
    \end{lstlisting}

    \subsection{Gestion des Erreurs Syntaxiques}\label{subsec:gestion-des-erreurs-syntaxiques}

    Un aspect essentiel du \textit{Parser} est sa capacité à gérer les erreurs syntaxiques comme nous le voyons dans le code ci-dessus.
    Lorsque le programme source ne respecte pas les règles de la grammaire, des messages d'erreur descriptifs sont générés, indiquant la ligne et le token attendu par rapport au token reçu, facilitant la localisation et la correction des erreurs par les développeurs.
    On a notamment appliqué le \textit{Panic Mode} pour gérer les erreurs syntaxiques.
    Le \textit{Parser} continue à analyser le programme source jusqu'à la fin tout en indiquant les erreurs rencontrées.

    \section{Construction de l'Arbre Abstrait Syntaxique pour canAda}\label{sec:construction-de-l'arbre-abstrait-syntaxique-pour-canada}

    La construction de l'arbre abstrait syntaxique (AST) est une étape essentielle du processus de compilation du langage \textit{canAda}.
    L'AST représente la structure syntaxique du programme source d'une manière qui est à la fois concise et facile à manipuler pour les étapes suivantes de la compilation.

    \subsection{Structure et Fonctionnement de l'AST}\label{subsec:structure-et-fonctionnement-de-l'ast}

    Notre système d'AST est construit autour de la classe \textit{ASTNode}, qui sert de classe de base pour les différents types de nœuds de l'arbre.
    Chaque nœud spécifique, comme \textit{OperatorNode}, \textit{ParameterNode}, ou \textit{ProgramNode}, hérite de \textit{ASTNode} et représente une construction syntaxique spécifique du langage.

    Par exemple, \textit{OperatorNode} représente une opération arithmétique ou logique, tandis que \textit{ProgramNode} représente la structure globale du programme \textit{canAda}.

    \begin{lstlisting}[label={lst:lstlisting13}]
public class ProgramNode extends ASTNode {
    private ProcedureDeclarationNode rootProcedure;

    public void setRootProcedure(ProcedureDeclarationNode rootProcedure) {
        this.rootProcedure = rootProcedure;
        rootProcedure.setParent(this);
    }
}
    \end{lstlisting}

    \begin{lstlisting}[label={lst:lstlisting15}]
public class OperatorNode extends ASTNode {
    private String operator;

    public OperatorNode(String operator) {
        this.operator = operator;
    }

}
    \end{lstlisting}

    Et ainsi de suite pour chaque nœud de l'arbre.
    On utilise alors notre fonction \textit{Override} \textit{toString()} pour afficher l'arbre abstrait syntaxique de manière recursive qui est dans notre classe abstraite dont extend nos différents nœuds.
    Ainsi on a juste a appeler la fonction \textit{toString()} sur le nœud racine de l'arbre pour afficher l'arbre abstrait syntaxique qui récupère les différents nœuds de l'arbre et les affiche de manière récursivee en récupérant les différents attributs de chaque nœud.

    \begin{lstlisting}[label={lst:lstlisting14}]
public String toString() {
    Field[] fields = this.getClass().getDeclaredFields();
    String className = this.getClass().getSimpleName();
    StringBuilder res = new StringBuilder(colorize(className, Attribute.YELLOW_TEXT()) + " : { \n");
    if (isJson) {
        res = new StringBuilder("{ \n");
    }
    int lastIndex = fields.length - 1;

    for (int i = 0; i < fields.length; i++) {
        Field field = fields[i];
        field.setAccessible(true);
        try {
            Object attributeValue = field.get(this);
            if (attributeValue instanceof String) {
                attributeValue = colorize("\"" + attributeValue + "\"", Attribute.GREEN_TEXT());
            }
            if (attributeValue == null) {
                attributeValue = colorize("null", Attribute.BRIGHT_MAGENTA_TEXT());
            }
            res.append("\t").append("\"").append(colorize(field.getName(), Attribute.RED_TEXT())).append("\"").append(" : ").append(attributeValue);
            if (i < lastIndex || !isJson) {
                res.append(",");
            }
            res.append(" \n");

        } catch (IllegalAccessException e) {
            System.err.println("Erreur lors de l'acces au champ " + field.getName());
        }
    }
    res.append("}");
    return format(res.toString());
}
    \end{lstlisting}

    \subsection{Représentation des Structures Syntaxiques}\label{subsec:representation-des-structures-syntaxiques}

    Les nœuds de l'AST capturent les éléments essentiels des structures syntaxiques du programme, comme les opérations, les paramètres, et la structure globale du programme.
    Par exemple, \textit{OperatorNode} représente une opération arithmétique ou logique, tandis que \textit{ProgramNode} représente la structure globale du programme \textit{canAda}.

    \subsection{Rôle dans le Processus de Compilation}\label{subsec:role-dans-le-processus-de-compilation}

    L'AST joue un rôle central dans le processus de compilation.
    Après l'analyse syntaxique, le programme source est transformé en un AST, qui est ensuite utilisé pour les étapes de vérification sémantique, d'optimisation, et de génération de code.
    Cette représentation permet une manipulation plus aisée et plus efficace du programme source.

    \section{Tables des symboles}

    \subsection{Structure de donnée}
    Les tables des symboles sont des structures de données qui stockent des informations sur les identificateurs du programme, comme les variables, les fonctions, et les procédures. \\

    Une table des symboles est implémentée sous la forme d'une table de hashage, avec comme clé le nom de l'identificateur et comme valeur un objet de type \textit{Symbol} qui contient des informations sur l'identificateur. \\

    Quant à l'organisation des ces tables, elles suivent toutes le schéma suivant:  a chaque bloc de porté (une fonction ou une procédure) on crée une nouvelle table des symboles qui est empilé dans une pile. Grâce à cette pile, nous pouvons réaliser les contrôles sémantiques au niveau des déclarations (prise en compte des scopes supérieurs) en remottant la pile jusqu'a trouver l'identificateur recherché. A la fin d'un bloc de porté, nous dépilons la dernière table de la pile.  \\

    Voici une illustration de l'analyse sémantique d'une fonction :
    \begin{lstlisting}[label={lst:lstlisting15}]
    @Override
    public void visit(FunctionDeclarationNode node) throws Exception {

        // Add the function to the current scope
        scopeStack.addSymbolInScopes(node.toSymbol(), node.getConcernedLine());

        // Create a new scope
        enterScope(new SymbolTable(node.getIdentifier()));


        // Check the semantic here

        // Exit the scope
        scopeStack.exitScope();
    }
    \end{lstlisting}


    \subsection{Exemple}
    Voici un exemple de table des symboles  pour une fonction nommé \textit{perimetreRectangle} ayant deux paramètres \textit{larg} et \textit{long} et une variable locale \textit{p} :
    \begin{lstlisting}[label={lst:lstlisting16}]
Entering new scope -> creating new SymbolTable for perimetreRectangle  :
    larg -> Parameter { identifier = 'larg', type = 'integer', mode = IN, shift = 4 }
    long -> Parameter { identifier = 'long', type = 'integer', mode = IN, shift = 8 }
    p -> Variable { identifier = 'p', type = 'integer', shift = 12 }
    \end{lstlisting}

    On peut rapidement identifier la clé de la table (le nom de l'identificateur) et la valeur associée de type \textit{Parameter} ou \textit{Variable} qui contient des informations sur l'identificateur tel que le décalage dans la pile, le type, le mode, etc. \\

    La liste des tables des symboles est également utilisé lors de la génération de code.

    \section{Contrôles sémantiques}

    \subsection{Parcours de l'AST}

    Afin de garantir la cohérence du programme, nous avons implémenté plusieurs contrôles sémantiques. Ces contrôles sont effectués après la construction de l'AST.\\

    Nous parcourons l'arbre de haut en bas à l'aide du pattern Visitor qui nous permet de descendre dans les noeuds. A chaque noeud nous effectuons les contrôles sémantiques associé puis descendons dans les noeuds du dessous. Voici un exemple pour le noeud correspondant à l'assignation d'une valeur à une variable : \\

    \begin{lstlisting}[label={lst:lstlisting17}]
    @Override
    public void visit(AssignmentStatementNode node) throws Exception {
        node.getVariableReference().accept(this);
        node.getExpression().accept(this);
        node.checkIfAssignable();
    }
    \end{lstlisting}

    Ici, nous pouvons remarquer les deux premières lignes (\texttt{node.getVariableReference().accept(this);} et \texttt{node.getExpression().accept(this);}) de la fonction qui permettent de descendre dans l'arbre et d'effectuer les contrôles sémantiques de la variable auquel va être assigné la valeur de l'expression ainsi que l'expression elle même. Ensuite on appelle la méthode qui vérifie si l'expression peut être assigné à la variable.


    \subsection{Implémentation}
    Voici une liste des contrôles sémantiques que nous avons implémentés :
    \begin{itemize}
        \item \textbf{Déclaration de variables} : Vérification de la déclaration des variables, si elles sont bien déclarées avant d'être utilisées.
        \item \textbf{Déclaration de fonctions et procédures} : Vérification de la déclaration des fonctions et procédures, si elles sont bien déclarées avant d'être utilisées.
        \item \textbf{Déclaration de types} : Vérification de la déclaration des types (Access, Record, Type)
        \item \textbf{Duplication de symbole} : Vérification de la duplication des symboles, si les symboles sont uniques dans le même scope.
        \item \textbf{Type des expressions} : Vérification du type des expressions, si les types des opérandes sont compatibles avec l'opérateur.
        \item \textbf{Type des variables} : Vérification du type des variables, si les types des variables sont compatibles avec les opérations effectuées.
        \item \textbf{Type des paramètres} : Vérification du type des paramètres, si les types des paramètres sont compatibles avec les types des arguments.
        \item \textbf{Type de retour} : Vérification du type de retour des fonctions, si le type de retour est compatible avec le type de la fonction.
        \item \textbf{Nombre de paramètres pour fonctions et procédures} : Vérification du nombre de paramètres pour les fonctions et procédures, si le nombre de paramètres est correct.
        \item \textbf{Vérification des paramètres IN et INOUT} : Vérification des paramètres IN et INOUT.
    \end{itemize}


    \section{Génération de Code}
    Une fois l'AST, les tables des symboles et les contrôles sémantiques complétés, la phase de génération de code peut commencer. Nous utilisons l'AST ainsi que les la liste des tables des symboles pour générer le code final en ASM UAL ARM 32 bits.

    \subsection{Parcours de l'AST}
    Pour générer le code, nous parcourons l'AST dans la classe \textit{ASMGenerator} de la même manière que l'analyse sémantique avec le pattern Visitor. Nous reconstruisons également la pile de table des symboles au fur et à mesure de la génération. Pour chaque noeud, nous générons le code correspondant. Chaque noeud est responsable uniquement de la génération de son propre code, sauf pour quelques exceptions où nous avons besoin de plus de contexte au moment de la génération (par exemple pour les appels de fonctions avec des paramètres record). \\

    \subsection{Exemple}
    Afin d'illustrer la génération de code, voici la partie pour le noeud gérant les retours de fonctions :
    \begin{lstlisting}[label={lst:lstlisting18}]
@Override
public void visit(ReturnStatementNode node) throws Exception {
    if(node.getExpression() != null) {
        node.getExpression().accept(this);
        Type type = (Type) scopeStack.findSymbolInScopes(node.getExpression().getType(scopeStack));
        int shift = 2 * 4 + type.getSize();
        if (type instanceof Record record) {
            this.output.append("""
                    \t MOV     R1, R9 ; Load field in R0
                    \t ADD   R2, R11, #%s ; Store return value for in stack-frame
                    """.formatted(shift));
            this.output.append(saveRecordInStack(record, 0));
        } else {
            this.output.append("""
                    \t STR     R0, [R11, #%s] ; Store return value for in stack-frame
                    """.formatted(shift));
        }
    }
    this.output.append("""
            \t MOV     R13, R11 ; Restore frame pointer
            \t LDR     R11, [R13] ; Restore caller's frame pointer
            \t ADD     R13, R13, #4 ;
            \t LDMFD   R13!, {R10, PC} ; Restore caller's frame pointer and return ASM address
            """);

}
    \end{lstlisting}

    On peut voir la façon dont on descend dans l'arbre (\texttt{node.getExpression().accept(this)}) et comment on génère le code correspondant à ce noeud. On peut ensuite déterminer le type de l'expression grâce à notre pile de table des symboles afin de séparé le cas d'un record. En effet, si le type de l'expression est un record alors on va appeler une fonction qui générer le code permettant de recopier un record d'une adresse stocker dans R1 à une adresse stocker dans R2. Enfin on restaure le contexte de la fonction appelante.

    \subsection{Schémas de traduction}
    \subsubsection{Déclaration de fonction}

    Dans un premier temps, les appels de fonctions ont été un problème au niveau de la sortie ASM. En effet ADA permet de déclarer des fonctions dans des fonctions et ainsi de suite, cependant cette structure ne correspond pas à la structure d'un programme en ASM (Chaque fonction aura son étiquette et sera isolée des autres). \\
    Afin de résoudre ce problème nous avons décidé de trier les déclarations en ne traduisant que ce celle qui ne sont pas une déclaration de fonction ou procédure. Poursuivre par la traduction la fonction (ou procédure) courante et seulement après traduire les déclarations de fonctions et procédure. Ceci permet de garder une structure ASM où chaque nouvelle fonction est bien a part des autres. \\

    Pour la génération de code d'une fonction, on commence par sauvegarder l'environnement de la fonction appelante et à mettre en place le nouveau, c'est à dire le frame pointer, la chaînage statique et le chaînage dynamque. Voici le code correspondant :
    \begin{lstlisting}
    this.output.append(symbol.getIdentifier()).append("\n").append("""
                \t STMFD   R13!, {R10, LR} ; Save caller's frame pointer and return ASM address
                \t MOV     R10, R9 ; Set up new static link
                \t SUB     R13, R13, #4
                \t STR     R11, [R13]
                \t MOV     R11, R13 ; Set up new frame pointer
                """);
    \end{lstlisting}

    Ensuite, nous récupérons les paramètres de la fonction en distinguant le cas d'un paramètre de type record nécessitant plusieurs instructions pour recopier chaque champs dans le paramètre. Voici le code correspondant :
    \begin{lstlisting}
    int counter = symbol.getParametersSize() + 2 *4 + type.getSize();
        for (ParameterNode param : node.getParameters()) {
            Type paramType = (Type) scopeStack.findSymbolInScopes(param.getType().getIdentifier());
            if(paramType instanceof Record record) {
                this.output.append("""
                            \t ADD     R1, R11, #%s ; Load field in R0
                            \t SUB     R2, R13, #4 ; Store argument for %s in stack-frame
                            """.formatted(counter,symbol.getIdentifier()));
                this.output.append(saveRecordInStack(record, 0));
                this.output.append("""
                            \t SUB     R13, R13, #%s ;
                            """.formatted(record.getSize()));
            } else {
                this.output.append("""
                    \t LDR     R0, [R11, #%s] ; Load parameter %s in R0
                    \t STMFD   R13!, {R0} ; Store parameter %s in stack-frame
                    """.formatted(counter, param.getIdentifier(), param.getIdentifier()));

            }
            counter-=paramType.getSize();


        }
    \end{lstlisting}

    Ici nous pouvons voir que l'on calcul le décalage permettant de retrouver les paramètres en prenant en compte la taille des paramètres, la taille du type de retour, ainsi qu'une constante (\texttt{2*4}) correspondant au chaînage statique et dynamique.

    L'implémentation du chaînage statique et dynamique nous permet de retrouver n'importe quel variable notamment lors de l'accès à une variable global dans une fonction récursive. \\

    Le code complet pour la partie déclaration de fonction est disponible en annexe.

    \subsubsection{Appels de fonctions}
    Pour la génération du code d'un appel des fonction, on commence par recopier les paramètres de la fonction, voici le code :
    \begin{lstlisting}
    node.getArguments().forEach(arg -> {

            arg.accept(this);
            if((Type) scopeStack.findSymbolInScopes(arg.getType(scopeStack)) instanceof Record record) {
                this.output.append("""
                        \t MOV     R1, R9 ; Load field in R0
                        \t SUB   R2, R13, #4 ; Store argument for %s in stack-frame
                        """.formatted(symbol.getIdentifier()));
                this.output.append(saveRecordInStack(record, 0));
                this.output.append("""
                        \t SUB   R13, R13, #%s ; Save space for argument
                        """.formatted(record.getSize()));
            } else {
                this.output.append("""
                        \t STMFD   R13!, {R0} ; Save argument
                        """);
            }
    });
    \end{lstlisting}

    Une fois de plus, on distingue le cas des records auxquels on doit recopier les champs un par un grâce à la méthode \texttt{saveRecordInStack(record, 0)} expliqué plus bas. \\

    Ensuite on prépare l'appel en laissant un espace pour la valeur de retour( qui peut être un record), puis après l'appel on récupère la valeur de retour dans R0. Voici le code correspondant :
    \begin{lstlisting}
    if(symbol instanceof Function function) {
        Type type = (Type) scopeStack.findSymbolInScopes(function.getReturnType());
        this.output.append("""
                \t SUB     R13, R13, #%s ; Save space for return value
                """.formatted(type.getSize()));

        this.output.append(findAddress(node.getIdentifier()));

        this.output.append("""
                \t BL      %s ; Branch link to %s (it will save the return address in LR)
                """.formatted(symbol.getIdentifier(), symbol.getIdentifier()));

        int shift = ASMUtils.getVariableReferenceShift(function.getReturnType(), node.getNextExpression());
        this.output.append("""
                \t ADD     R9, R13, #%s ; Store the return value address in R0
                \t LDR     R0, [R9] ; Load the return value in R0
                """.formatted(type.getSize() - 4 - shift));

        this.output.append("""
                \t ADD     R13, R13, #%s ; Remove arguments and return value from stack
                """.formatted(symbol.getParametersSize() + type.getSize()));
    } else {
        this.output.append(findAddress(node.getIdentifier()));
        this.output.append("""
                \t BL      %s ; Branch link to %s (it will save the return address in LR)
                """.formatted(symbol.getIdentifier(), symbol.getIdentifier()));
        this.output.append("""
                \t ADD     R13, R13, #%s ; Remove arguments and return value from stack
                """.formatted(symbol.getParametersSize()));
    }
    \end{lstlisting}

    Ici, on sépare les fonctions des procédures car les procédures ne nécessitent pas d'instructions pour la valeur de retour. Après l'appel, on réduit la taille de notre pile en enlevant les arguments et valeurs de retour n'étant plus utile. \\

    De plus, nous avons ajouter des instructions particulières pour pouvoir afficher des valeurs. En effet nous avons implémenté 2 fonctions spéciales (put et putInt afin d'afficher des éléments sur la sortie standard).  Ces fonctions put et putInt ont été réalisées à l'aide de la librairie visUAL2 d'Alexandre Duchesne. Voici le code correspondant :
    \begin{lstlisting}
    if (symbol.getIdentifier().equals("put")) {
        node.getArguments().forEach(arg -> {
            try {
                arg.accept(this);
                this.output.append("""
                        \t SUB SP, SP, #4   ; réservez 4 octets pour le 0
                        \t MOV R1, #0
                        \t STR R1, [SP]
                        \t SUB SP, SP, #4   ; réservez 4 octets pour la valeur (ou plus)
                        \t STR R0, [SP]     ; stockez la valeur
                        \t MOV R0, SP       ; adresse de la valeur (ici SP, mais peut être n'importe quelle adresse)
                        \t BL println
                        \t ADD SP, SP, #8   ; libérez la pile
                        """);

            } catch (Exception ex) {
                throw new RuntimeException(ex);
            }
        });
        return;
    }

    if (symbol.getIdentifier().equals("putInt")) {
        node.getArguments().forEach(arg -> {
            try {
                arg.accept(this);
                this.output.append("""
                        \t LDR R3, =STR_OUT       ; on charge l'adresse de la valeur
                        \t BL to_ascii          ; on convertit l'entier en chaîne de caractères
                        \t LDR R0, =STR_OUT       ; on charge l'adresse de la chaîne de caractères
                        \t BL println           ; on affiche la chaîne de caractères
                        """);
            } catch (Exception ex) {
                throw new RuntimeException(ex);
            }
        });
        return;
    }
    \end{lstlisting}

    Le code complet de l'appel de fonction est disponible en annexe.





    \subsubsection{Conditionnelles imbriquées}

    Les conditionnelles imbriquées ont été gérées de manière naturelle. Chaque if se voit attribuer une étiquette unique basée sur un ID. Ainsi, chaque if est isolé des autres et peut être traité de manière indépendante. L'imbrication de ceux ci ne pose donc aucun soucis. Voici le code pour la génération de code pour les conditionnelles :

    \begin{lstlisting}
@Override
public void visit(IfStatementNode node) throws Exception {
    String ifTrueLabel = "if_true_" + Context.background().getUniqueLabelId();
    String ifEndLabel = "if_end_" + Context.background().getUniqueLabelId();

    node.getCondition().accept(this);

    this.output.append("""
            \t CMP     R0, #0 ; Compare condition
            \t BEQ     %s ; Branch if condition is false
            """.formatted(ifEndLabel));

    if (node.getElseBranch() != null) {
        node.getElseBranch().accept(this);
    }

    output.append("\t B       ").append(ifEndLabel).append("\n");

    output.append(ifTrueLabel).append("\n");

    node.getThenBranch().accept(this);

    output.append(ifEndLabel).append("\n");
}
    \end{lstlisting}

    On remarque au début la génération des étiquettes uniques pour chaque if, puis la génération du code pour la condition, le branchement si la condition est fausse, le traitement du else si il existe, et enfin le traitement du then et la fin du if. Dans le cas où une conditionnelle est imbriquée, le code de l'imbriquée sera simplement généré entre le branchement du then et la fin de l'if, et se verra attribuer une étiquette unique.

    \subsection{Records}

    La gestion des records à travers les appels de fonctions ont été décrit au dessus. En terme général, les records sont traités comme des variables normales, avec un décalage dans la pile. Nous pouvons faire cela car leur taille est statique et connue à la compilation. Nous empilons donc de manière contigüe les différents champs du record, et nous les désemplilons de la même manière. Lorsque nous avons besoin de passer un record en argument, nous passons l'adresse du premier champs du record en argument, et nous utilisons le décalage pour accéder aux différents champs du record Voici la fonction permettant de calculer le décalage au sein d'un record. \\

    \begin{lstlisting}

        public static int getVariableReferenceShift(String typeIdent, VariableReferenceNode nextExpression) {
        int shift = 0;
        while (nextExpression != null) {
            Record record = (Record) scopeStack.findSymbolInScopes(typeIdent);
            assert record != null;
            Variable field = record.getField(nextExpression.getIdentifier());
            shift += field.getShift();
            typeIdent = field.getType();
            nextExpression = nextExpression.getNextExpression();
        }
        return shift;
    }
    \end{lstlisting}

    Ici nous pouvons voir que nous parcourons les accès aux champs du record et récupérons l'addition du shift de chacun des champs. Grâce à cela nous pouvons avoir accès à un champ dans des records imbriqués.\\

    Nous avons également implémenté la comparaison de record. En effet, nous pouvons tester l'égalité de record, deux record seront égaux si tous leur champ le sont. Voici le code correspondant :
    \begin{lstlisting}
    public static String equalsRecord(Record record, String left, String right, int shift) {
        StringBuilder sb = new StringBuilder();
        for (Variable field : record.getFields()) {
            Type type = (Type) scopeStack.findSymbolInScopes(field.getType());
            if (type instanceof Record subRecord) {
                sb.append(equalsRecord(subRecord, left, right, field.getShift() + shift));
            } else {
                // On va chercher le champ pour left dans la pile avec findVariableAddress
                sb.append(findVariableAddress(left, null));
                sb.append("""
                        \t LDR     R1, [R9, #-%s] ; Load variable %s in R0
                        """.formatted(field.getShift() + shift, left));
                // On va chercher le champ pour right dans la pile avec findVariableAddress
                sb.append(findVariableAddress(right, null));
                sb.append("""
                        \t LDR     R2, [R9, #-%s] ; Load variable %s in R1
                        """.formatted(field.getShift() + shift, right));
                // On compare les deux champs
                sb.append("""
                        \t CMP     R1, R2 ; Compare operands
                        \t MOVNE   R0, #0 ; Set R2 to 1 if operands are not equal
                        """);
            }
        }
        return sb.toString();
    }
    \end{lstlisting}

    Ici nous pouvons tester l'égalité de deux records et ceux même si un champ est également un record car la méthode fonctionne récursivement.


    \section{Tests et Validation}\label{sec:tests-et-validation}

    \subsection{Pour un code source valide}\label{subsec:pour-un-code-source-valide}

    Voici un code source valide en canAda qui permet de tester notre compilateur :

    \begin{lstlisting}[label={lst:lstlisting16}]
with Ada.Text_IO; useAda.Text_IO;
procedure Main is
    A : Integer := 5;
    B : Integer := 10;
    Sum : Integer;
begin
    Sum := A + B;
end Main;
    \end{lstlisting}

    On obtient alors après l'analyse lexicale et syntaxique la sortie suivante, on l'a découpée en 3 parties pour plus de lisibilité et laissée sur fond noir pour faciliter la lisibilité des couleurs :

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.3\textwidth]{sortie1}
        \hfill
        \includegraphics[width=0.3\textwidth]{sortie2}
        \hfill
        \includegraphics[width=0.3\textwidth]{sortie3}
        \caption{Sortie découpée de gauche à droite}\label{fig:figure4}
    \end{figure}

    Et on obtient l'arbre abstrait suivant en sortie et donc ici en json :

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{arbre_json}
        \caption{Arbre abstrait}\label{fig:figure5}
    \end{figure}

    Et à l'aide de notre script python et de graphviz on obtient l'arbre abstrait suivant :

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{arbre_draw}
        \caption{Arbre abstrait}\label{fig:figure6}
    \end{figure}

    La partie de génération des TDS et des contrôles sémantiques démarre à présent. Afin de montrer quelque chose de plus parlant que le programme ci-dessus, on prend a présent ce programme :

    \begin{lstlisting}[label={lst:lstlisting16}]
with Ada.Text_IO; use Ada.Text_IO;
procedure unDebut is

function perimetreRectangle(larg : integer; long : integer) return integer is
p : integer;
begin
    p := 1+2+3 ;
return p ;
end perimetreRectangle;

    -- VARIABLES
choix : integer ;
    -- PROCEDURE PRINCIPALE
begin
choix := perimetreRectangle(5, 10);
end unDebut ;
    \end{lstlisting}

    On obtient ces différentes tables :

    \begin{lstlisting}
Entering new scope -> creating new SymbolTable for root  :
    character -> Type { identifier = 'character', size = 4, shift = 0 }
    integer -> Type { identifier = 'integer', size = 4, shift = 0 }
    unDebut -> Procedure { identifier = 'unDebut', indexedParametersTypes = '[]', shift = 0 }
    put -> Procedure { identifier = 'put', indexedParametersTypes = '[character]', shift = 0 }


Entering new scope -> creating new SymbolTable for unDebut  :
    perimetreRectangle -> Function { identifier = 'perimetreRectangle', indexedParametersTypes = '[integer, integer]', returnType = 'integer', shift = 0 }
    choix -> Variable { identifier = 'choix', type = 'integer', shift = 4 }


Entering new scope -> creating new SymbolTable for perimetreRectangle  :
    larg -> Parameter { identifier = 'larg', type = 'integer', mode = IN, shift = 4 }
    long -> Parameter { identifier = 'long', type = 'integer', mode = IN, shift = 8 }
    p -> Variable { identifier = 'p', type = 'integer', shift = 12 }
    \end{lstlisting}

    Les contrôles sémantiques sont passés avec succès, et le code généré est le suivant :

    \begin{lstlisting}
unDebut
	 STMFD   R13!, {R11, LR} ; Main environment setup
	 MOV     R11, R13 ; Set up new frame pointer
	 SUB     R13, R13, #4 ; Save space for choix in stack-frame
	 MOV     R0, #5 ; Load literal value in R0
	 STMFD   R13!, {R0} ; Save argument
	 MOV     R0, #10 ; Load literal value in R0
	 STMFD   R13!, {R0} ; Save argument
	 SUB     R13, R13, #4 ; Save space for return value
	 BL      perimetreRectangle ; Branch link to perimetreRectangle (it will save the return address in LR)
	 LDR     R0, [R13] ; Load return value
	 ADD     R13, R13, #4 * 3 ; Remove arguments and return value from stack
	 MOV     R10, R11
	 STR     R0, [R10, #-4] ; Assign right expression (assuming result is in R0) to left variable choix
	 END     ; Program ends here
perimetreRectangle
	 STMFD   R13!, {R11, LR} ; Save callers frame pointer and return ASM address
	 MOV     R11, R13 ; Set up new frame pointer
	 LDR     R5, [R11, #4 * 4] ; Load parameter larg in R5
	 STMFD   R13!, {R5} ; Store parameter larg in stack-frame
	 LDR     R5, [R11, #4 * 3] ; Load parameter long in R5
	 STMFD   R13!, {R5} ; Store parameter long in stack-frame
	 SUB     R13, R13, #4 ; Save space for p in stack-frame
	 MOV     R0, #3 ; Load literal value in R0
	 STMFD   R13!, {R0} ; Store the right operand in the stack
	 MOV     R0, #2 ; Load literal value in R0
	 LDMFD   R13!, {R1} ; Load the right operand in R1
	 ADD     R0, R0, R1 ; Add operands
	 STMFD   R13!, {R0} ; Store the right operand in the stack
	 MOV     R0, #1 ; Load literal value in R0
	 LDMFD   R13!, {R1} ; Load the right operand in R1
	 ADD     R0, R0, R1 ; Add operands
	 MOV     R10, R11
	 STR     R0, [R10, #-12] ; Assign right expression (assuming result is in R0) to left variable p
	 MOV     R10, R11
	 LDR     R0, [R10, #-12] ; Load variable p in R0
	 STR     R0, [R11, #4 * 2] ; Store return value for in stack-frame
	 MOV     R13, R11 ; Restore frame pointer
	 LDMFD   R13!, {R11, PC} ; Restore callers frame pointer and return ASM address
    \end{lstlisting}

    La phase de génération de code ajoute également des commentaires automatiques pour faciliter la compréhension du code généré. \\

    \subsection{Pour un code source invalide}\label{subsec:pour-un-code-source-invalide}
    \subsubsection{Erreurs syntaxiques}

    Voici un code source invalide en canAda qui permet de tester notre compilateur, on a volontairement rajouter un ; en trop à la fin de la ligne 5 :

    \begin{lstlisting}[label={lst:lstlisting17}]
with Ada.Text_IO; useAda.Text_IO;
procedure Main is
    A : Integer := 5;
    B : Integer := 10;
    Sum : Integer;
begin ;
    Sum := A + B;
end Main;
    \end{lstlisting}

    On obtient alors après l'analyse lexicale et syntaxique la sortie suivante, on l'a découpée en 3 parties pour plus de lisibilité et laissée sur fond noir pour faciliter la lisibilité des couleurs :

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.3\textwidth]{sortie1_err}
        \hfill
        \includegraphics[width=0.3\textwidth]{sortie2_err}
        \hfill
        \includegraphics[width=0.3\textwidth]{sortie3_err}
        \caption{Sortie découpée de gauche à droite}\label{fig:figure7}
    \end{figure}

    Et on obtient les erreurs et les warnings suivantes :

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{syntax_err}
        \caption{Erreurs}\label{fig:figure8}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{syntax_warn}
        \caption{Warnings}\label{fig:figure9}
    \end{figure}
    \subsubsection{Erreurs sémantiques}

    Voici un code source valide syntaxiquement mais sémantiquement incorrect :

    \begin{lstlisting}[label={lst:lstlisting18}]
with Ada.Text_IO; use Ada.Text_IO;
procedure unDebut is

function perimetreRectangle(larg : integer; long : integer) return integer is
p : integer;
c : character;
begin
    p := 2 ;
    p := 'C' ;
    c := 'C' ;
    return c ;
end perimetreRectangle;

choix : integer ;
begin
choix := perimetreRectangle(5, 10, 15);
end unDebut ;
    \end{lstlisting}

    On peut voir ici plusieurs erreur, tel que l'assignation à \texttt{p} d'un char, le retour d'un char dans une fonction qui retourne un int (\texttt{perimetreRectangle}), et l'appel de la fonction \texttt{perimetreRectangle} avec un nombre incorrect de paramètres. \\
    Nous obtenons alors les erreurs suivantes :
    \begin{lstlisting}
Semantic errors:
	Line 9: Type mismatch: expected integer but got character
	Line 11: The return type of the FUNCTION does not match the type of the expression (expected integer but got character)
	Line 17: The FUNCTION perimetreRectangle expects 2 arguments but got 3
    \end{lstlisting}

    On peut ainsi voir que notre compilateur est capable de gérer les erreurs syntaxiques et de les afficher de manière claire et précise.
    Ainsi que de nous aider à le corriger notamment à travers les warnings et le \textit{Panic Mode} qui permet de continuer à analyser le programme source jusqu'à la fin tout en indiquant les erreurs rencontrées.
    Il analyse également la sémantique du programme et vérifie que les types sont compatibles entre eux.


    Ce qui conclue la partie sur les tests et la validation de notre compilateur.
    Bien évidemment, de nombreux autres tests ont été réalisés pour valider notre compilateur, ceux-ci sont disponible dans la source du projet. \\

    Vous pourrez trouver en annexe notre programme de démonstration. Celui-ci permet de mettre en valeur toutes les fonctionnalités du compilateur, à travers un jeu de combat.
    \section{Gestion de projet}\label{sec:gestion-de-projet}

    \subsection{Équipe de projet}\label{subsec:equipe-de-projet}
    Ce projet est un projet local réalisé en groupe de 3 personnes~:
    \begin{itemize}
        \item Alexis MARCEL
        \item Lucas LAURENT
        \item Noé STEINER
    \end{itemize}

    \subsection{Organisation au sein de l’équipe projet}\label{subsec:organisation-au-sein-de-lequipe-projet}
    Nous avons réalisé plusieurs réunions, en présentiel dans les locaux de Télécom Nancy mais la plupart de notre collaboration a eu lieu sur Discord.
    Ces réunions nous ont permis de mettre en commun nos avancées régulièrement, de partager nos connaissances sur des problématiques et de nous organiser de manière optimale.
    En plus des réunions d'avancement régulières, nous avons également réalisé des réunions techniques afin de résoudre un problème ou bien de réfléchir à la conception.

    Ensuite, nous avons utilisé GitLab pour gérer les différentes versions du développement de notre application, ainsi que les différentes
    branches nous permettant de travailler simultanément sans conflit.

    \subsection{Matrice RACI}\label{subsec:matrice-raci}
    Voici la matrice RACI de notre projet, elle nous a permis de nous organiser et de répartir les tâches de manière efficace, on remarque que personne n'approuve les tâches car nous avons travaillé en groupe et que nous avons tous approuvé les tâches entre nous.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\textwidth]{RACI}
        \caption{Matrice RACI}\label{fig:figure3}
    \end{figure}

    \subsection{Répartition du Temps de Travail sur le Projet}\label{subsec:repartition-du-temps-de-travail-sur-le-projet}

    On peut voir que la répartition du temps de travail est équilibrée entre les membres de l'équipe, ce qui a permis une contribution égale de tous les membres de l'équipe :
    \newline

    \begin{tabular}{@{}llll@{}}
        \toprule
        Tâche & Lucas & Noé & Alexis \\ \midrule
        Grammaire & 10h & - & - \\
        Structure du Lexer & - & 2h & 4h \\
        Lecture du fichier (token par token) & - & 5h & 7h \\
        Implémentation des Token et des Tag & 2h & 2h & 2h \\
        Structure du Parser & 1h & - & - \\
        Gestion des erreurs & 4h & 4h & - \\
        Implémentation des règles & 3h & 3h & 3h \\
        Structure de l'arbre abstrait & - & 2h & - \\
        Implémentation des différents nodes & - & 6h & 6h \\
        Rédaction du rapport PCL1 & 4h & - & - \\
        \midrule
        Total PCL1 & 24h & 24h & 22h \\ \bottomrule
        Tables des symboles & 2h & 5h & 5h \\
        Structure de l'analyse sémantique & 2h & 2h & 9h \\
        Analyse sémantique & 9h & 9h & 9h \\
        Tests & 5h & - & - \\
        Génération de code & 20h & 20h & 24h \\
        Rédaction du rapport PCL2 & 1h & 2h & 1h \\
        \midrule
        Total PCL2 & 38h & 36h & 48h \\ \bottomrule
        \midrule
        Total PCL1 + PCL2 & 62h & 62h & 69h \\ \bottomrule

    \end{tabular}

    \section{Conclusion}\label{sec:conclusion}
    Ce rapport a présenté en détail le processus de développement d'un compilateur pour le langage \textit{canAda}, réalisé dans le cadre du module PCL1 à TELECOM Nancy.
    Le projet a débuté par la transformation de la grammaire originale en une grammaire LL(1), adaptée pour une analyse syntaxique précise.
    Cette transformation a impliqué tout d'abord d'avoir une grammaire explicite sans regex, puis l'élimination de la récursivité à gauche, la factorisation, et la gestion des priorités de calculs pour assurer une analyse déterministe.
    \newline
    L'analyse lexicale a été effectuée par le \textit{Lexer}, un composant clé qui convertit le code source en tokens, en s'appuyant sur un ensemble de règles prédéfinies et un système efficace de lecture en avance et d'une astuce pour déterminer la fin d'un token ce qui nous a permis de nous passer d'un automate à états finis.
    La classe \textit{Parser}, quant à elle, a permis l'analyse syntaxique à travers la récupération du flux de \textit{Token} du programme source et l'application des règles établies dans le tableau LL(1), tout en gérant les erreurs/warnings syntaxiques de manière robuste permettant ainsi de continuer à analyser le programme source jusqu'à la fin tout en indiquant les erreurs rencontrées pour aider le développeur à les corriger.
    \newline
    La construction de l'arbre abstrait syntaxique (AST) a été une étape cruciale, permettant une représentation concise et manipulable du programme source pour les étapes ultérieures de la compilation.
    Chaque nœud de l'AST, tel que \textit{OperatorNode} ou \textit{ProgramNode}, a capturé des éléments essentiels des structures syntaxiques du langage \textit{canAda}.
    \newline
    PCL2 nous a permis d'implémenter les Symbol Tables, les contrôles sémantiques et la génération de code. Les Symbol Tables stockent des informations sur les identificateurs du programme, tandis que les contrôles sémantiques garantissent la cohérence du programme en vérifiant les types et les structures syntaxiques. La génération de code a permis de traduire l'AST en code ASM UAL ARM 32 bits, en utilisant un pattern de Double Dispatch : Visitor pour parcourir l'AST et générer le code correspondant à chaque nœud.

    La répartition du temps de travail sur les différentes tâches a été équilibrée, assurant ainsi une contribution égale de tous les membres de l'équipe.

    En conclusion, ce projet a non seulement abouti à la création d'un compilateur fonctionnel pour \textit{canAda} mais a également permis aux membres de l'équipe d'approfondir leurs compétences en informatique, notamment dans les domaines de l'analyse lexicale et syntaxique, ainsi que dans la construction et la manipulation d'arbres abstraits.
    Ce projet représente une étape significative dans notre parcours d'ingénieurs en informatique, nous préparant efficacement à des applications concrètes dans divers secteurs technologiques.

    Il a également renforcé notre compréhension des fondamentaux de la compilation, une compétence essentielle pour tout développeur de logiciels ainsi que pour tout ingénieur en informatique.

    \section{Annexe}\label{sec:annexe}

    \subsection{Code complet de génération du code de déclaration de fonction}


    \begin{lstlisting}

    public void visit(FunctionDeclarationNode node) throws Exception {
        enterScope();
        Function symbol = (Function) scopeStack.findSymbolInScopes(node.getIdentifier());
        this.output.append(symbol.getIdentifier()).append("\n").append("""
                \t STMFD   R13!, {R10, LR} ; Save caller's frame pointer and return ASM address
                \t MOV     R10, R9 ; Set up new static link
                \t SUB     R13, R13, #4
                \t STR     R11, [R13]
                \t MOV     R11, R13 ; Set up new frame pointer
                """);

        Type type = (Type) scopeStack.findSymbolInScopes(symbol.getReturnType());
        int counter = symbol.getParametersSize() + 2 *4 + type.getSize();
        for (ParameterNode param : node.getParameters()) {
            Type paramType = (Type) scopeStack.findSymbolInScopes(param.getType().getIdentifier());
            if(paramType instanceof Record record) {
                this.output.append("""
                            \t ADD     R1, R11, #%s ; Load field in R0
                            \t SUB     R2, R13, #4 ; Store argument for %s in stack-frame
                            """.formatted(counter,symbol.getIdentifier()));
                this.output.append(saveRecordInStack(record, 0));
                this.output.append("""
                            \t SUB     R13, R13, #%s ;
                            """.formatted(record.getSize()));
            } else {
                this.output.append("""
                    \t LDR     R0, [R11, #%s] ; Load parameter %s in R0
                    \t STMFD   R13!, {R0} ; Store parameter %s in stack-frame
                    """.formatted(counter, param.getIdentifier(), param.getIdentifier()));

            }
            counter-=paramType.getSize();


        }
        node.getBody().accept(this);
        scopeStack.exitScope();
    }
    \end{lstlisting}


    \subsection{Code complet de génération du code d'appel de fonction}


    \begin{lstlisting}
@Override
public void visit(CallNode node) throws Exception {
    Procedure symbol = (Procedure) scopeStack.findSymbolInScopes(node.getIdentifier());

    if (symbol.getIdentifier().equals("put")) {
        node.getArguments().forEach(arg -> {
            try {
                arg.accept(this);
                this.output.append("""
                        \t SUB SP, SP, #4   ; réservez 4 octets pour le 0
                        \t MOV R1, #0
                        \t STR R1, [SP]
                        \t SUB SP, SP, #4   ; réservez 4 octets pour la valeur (ou plus)
                        \t STR R0, [SP]     ; stockez la valeur
                        \t MOV R0, SP       ; adresse de la valeur (ici SP, mais peut être n'importe quelle adresse)
                        \t BL println
                        \t ADD SP, SP, #8   ; libérez la pile
                        """);

            } catch (Exception ex) {
                throw new RuntimeException(ex);
            }
        });
        return;
    }

    if (symbol.getIdentifier().equals("putInt")) {
        node.getArguments().forEach(arg -> {
            try {
                arg.accept(this);
                this.output.append("""
                        \t LDR R3, =STR_OUT       ; on charge l'adresse de la valeur
                        \t BL to_ascii          ; on convertit l'entier en chaîne de caractères
                        \t LDR R0, =STR_OUT       ; on charge l'adresse de la chaîne de caractères
                        \t BL println           ; on affiche la chaîne de caractères
                        """);
            } catch (Exception ex) {
                throw new RuntimeException(ex);
            }
        });
        return;
    }

    node.getArguments().forEach(arg -> {
        try {
            arg.accept(this);
            if((Type) scopeStack.findSymbolInScopes(arg.getType(scopeStack)) instanceof Record record) {
                this.output.append("""
                        \t MOV     R1, R9 ; Load field in R0
                        \t SUB   R2, R13, #4 ; Store argument for %s in stack-frame
                        """.formatted(symbol.getIdentifier()));
                this.output.append(saveRecordInStack(record, 0));
                this.output.append("""
                        \t SUB   R13, R13, #%s ; Save space for argument
                        """.formatted(record.getSize()));
            } else {
                this.output.append("""
                        \t STMFD   R13!, {R0} ; Save argument
                        """);
            }

        } catch (Exception ex) {
            throw new RuntimeException(ex);
        }
    });

    if(symbol instanceof Function function) {
        Type type = (Type) scopeStack.findSymbolInScopes(function.getReturnType());
        this.output.append("""
                \t SUB     R13, R13, #%s ; Save space for return value
                """.formatted(type.getSize()));

        this.output.append(findAddress(node.getIdentifier()));

        this.output.append("""
                \t BL      %s ; Branch link to %s (it will save the return address in LR)
                """.formatted(symbol.getIdentifier(), symbol.getIdentifier()));

        int shift = ASMUtils.getVariableReferenceShift(function.getReturnType(), node.getNextExpression());
        this.output.append("""
                \t ADD     R9, R13, #%s ; Store the return value address in R0
                \t LDR     R0, [R9] ; Load the return value in R0
                """.formatted(type.getSize() - 4 - shift));

        this.output.append("""
                \t ADD     R13, R13, #%s ; Remove arguments and return value from stack
                """.formatted(symbol.getParametersSize() + type.getSize()));
    } else {
        this.output.append(findAddress(node.getIdentifier()));
        this.output.append("""
                \t BL      %s ; Branch link to %s (it will save the return address in LR)
                """.formatted(symbol.getIdentifier(), symbol.getIdentifier()));
        this.output.append("""
                \t ADD     R13, R13, #%s ; Remove arguments and return value from stack
                """.formatted(symbol.getParametersSize()));
    }
}
    \end{lstlisting}

    \subsection{Programme de démonstration}
    \begin{lstlisting}
with Ada.Text_IO; use Ada.Text_IO;
procedure CombatSimulator is
    type Weapon is record
        damage : integer;
    end record;

    type Armor is record
        defense : integer;
    end record;

    type Character is record
        name : character;
        hp : integer;
        attack : integer;
        defense : integer;
        weapon : Weapon;
        armor : Armor;
    end record;



    Player1 : Character;
    Player2 : Character;

    function Attack (Player1 : in out Character; Player2 : in out Character) return Character is
    begin
        Player2.hp := Player2.hp - Player1.attack;
        return Player2;
    end Attack;

    function IsDead (Player : Character) return boolean is
    begin
        if Player.hp <= 0 then
            return True;
        else
            return False;
        end if;
    end IsDead;

    procedure printStats(Player : Character) is
    begin
        put(Player.name);
        putInt(Player.hp);
        return;
    end printStats;

    function initCharacter(name : character) return Character is
    player : Character;
    begin
        player.name := name;
        player.hp := 20;
        player.attack := 10;
        player.defense := 5;
        return player;
    end initCharacter;



begin
    Player1 := initCharacter('A');
    Player2 := initCharacter('B');

    printStats(Player1);
    printStats(Player2);

    Player2 := Attack(Player1, Player2);

    printStats(Player1);
    printStats(Player2);

    if IsDead(Player2) then
        put('D');
    else
        put('A');
    end if;

    Player2 := Attack(Player1, Player2);

    printStats(Player1);
    printStats(Player2);

    if IsDead(Player2) then
        put('D');
    else
        put('A');
    end if;

end CombatSimulator;

    \end{lstlisting}
\end{document}
